% !Tex root = ../main.tex

\chapter{Foundations}\label{chapter:foundations}

\section{Oncology guideline documents}
Qualitative analysis of the properties of oncology guideline documents.

\section{Vision-Language Models}
\Glspl{llm} are inherintley confined to processing exclusively text-based data. This limitation restricts their applicability in complex, real-world scenarios, where understanding and combining data from multiple modalities is crucial \autocite{vlm_frontier,qwen25vl}.\ \Gls{vlm} are a class of models which respond to these limitations by combining visual and textual processing capabilities into a single architecture \autocite{vlm_frontier}. These models find applications involving both the comprehension and generation of multimodal content, such as image captioning, and visual question answering \autocite{vlm_frontier}.

The typical architecture of \glspl{vlm} is depicted in \todo{figure}. The architecture consists of a text encoder, an image encoder, an image-text

% Acoording to \textcite{vlm_frontier}, \glspl{vlm} can be categorized into three classifications.

% \textbf{Vision-Language Understanding:} \Gls{vlu} includes models which are designed to comprehend and interpret visual and textual data and their relationships. Common applications for models of this classification are image classification and object detection \autocite{vlm_frontier}. Notable examples of \gls{vlu} models include CLIP \autocite{clip} and VLMo \autocite{vlmo}.

% \textbf{Text Generation with Multimodal Input:} Models of this classification excel in creating textual content by incorporating information from both visual and textual sources. Popular examples of this modality are the GPT family of models as well as the open-source Qwen

% \textbf{Multimodal Output with Multimodal Input:} These models further enhance the capabilities from previous groups by being able to generate both textual and visual content. 

% \Glspl{vlm} extend the capabilities of traditional \glspl{llm}, adding visual understanding to their natural language processing abilities \autocite{qwen25vl}.

\todo{Maybe need to add explanations for transformers?}\\

\section{Document Parsing}
Also known as document content extraction, \gls{dp} aims to convert unstructured and semi-structured documents into structured, machine readable data formats \autocite{parsingunveiled,omnidocbench}. During this process elements such as headings, tables, and figures are extracted from the document while preserving their structural relationships.\ \gls{dp} is crucial for many document-related tasks, providing access to previously unavailable information sources. Especially for \glspl{llm}, where leveraging additional training data is crucial for enhancing the model's factual accuracy and knowledge grounding, \gls{dp} plays an important rule \autocite{omnidocbench,mineru}. With the emergence of the \gls{rag} pardigm, \gls{dp} has also been critical in the creation of the knowledge database, as important information is often stored inside file formats which can not directly be processed by machines \autocite{docling}. While \gls{dp} is used for converting a range of document formats into machine-readable content, we will focus solely on the parsing of \gls{pdf} documents for the purposes of this thesis, as this is the datatype that the oncology guidelines are stored as.

Converting \gls{pdf} documents is particularly challenging due to their variable formatting, lack of standardization and focus on visual characteristics \autocite{docling}. The format not only includes digitally-born files but also includes photographed and scanned documents. Therefore \gls{dp} systems need to be able to adapt to a wide range of different layouts, image qualities and document types, such as academic papers, invoices or presentation slides \autocite{omnidocbench,intelligent_doc_parsing}. While there are many tools and implementations available for \gls{dp}\autocite{docling,mineru,mineru_vlm,unstructuredio}, most of them can be categorized into either modular pipeline systems or end-to-end VLM models.

\subsection{Modular Pipeline Systems}
Modular pipeline systems employ various different modules in a sequential order to perform \gls{dp}. This modular design enables the targeted optimization of individual components and flexibility integration of new modules and techniques \autocite{monkeyocr}. Additionally, by making use of lightweight models and integrating parallelization, pipeline systems can reach efficient parsing speeds \autocite{omnidocbench}. While different formations are possible, most implementations consist of three different stages \autocite{parsingunveiled}.

\textbf{\Glspl{dla}:} According to \textcite{parsingunveiled}, \gls{dla} refers to the identification of the structural elements of a document, such as paragraphs, section headers, tables, figures, and mathematical equations, as well as their respective bounding boxes \autocite{parsingunveiled,docling_heron}. There are two types of methods for performing \gls{dla}. Unimodal methods focus purely on visual features of the document in order to identify structural elements \autocite{parsingunveiled,pp_doclayout}. Notably, \gls{cnn}- and transformer-based methods adapt models initially designed for object detection tasks, such as the YOLO \autocite{yolo} and DETR \autocite{detr} families of models, to accurately identify structural elements in document images \autocite{parsingunveiled,docling_heron}. Hereby, transformer-based methods excell at capturing global relationships between structural elements at the cost of computational intensivity and expensive pretraining \autocite{parsingunveiled}.
The second type of \gls{dla} methods are multi-modal methods. Additionally to the visual representations, multi-modal methods also rely on the content and position of the pages' textual content, performing \gls{dla} using a \gls{vlm} \autocite{pp_doclayout,layoutlm_v3}. This approach allows more granular classifications and the analysis of highly complex layouts \autocite{parsingunveiled,pp_doclayout}.

\textbf{Content Extraction:} To extract the content of the identified structural elements different recognizers are applied to the element's region based on it's classification \autocite{parsingunveiled,mineru,docling}. For textual elements, such as paragraphs or section headings, the textual content is identified using \gls{ocr}.\ \gls{ocr} engines use techniques from computer vision in order to identify and extract text from images \autocite{parsingunveiled,ocr_survey}. Popular \gls{ocr} engines include EasyOCR \autocite{easyocr} and the Tesseract OCR engine \autocite{tesseract}. Additionally to extracting content using \gls{ocr}, \gls{dp} implementation often provide specific recognizers for additional element types \autocite{parsingunveiled,mineru}. Most commonly this includes a specific model for table structure recognition, referring to the extraction of table content as a structured file format, such as HTML, XML or Markdown \autocite{parsingunveiled,docling,mineru,unstructured_open_source}. Other options for class-specific recognizers include mathematical formula recognition and chart recognition \autocite{mineru,mineru_vlm,parsingunveiled}.

\textbf{Relation Integration:} During relation integration the identified elements are combined into the final output format. During this stage, rule-based methods and specialized \gls{ai} models may be employed, for example for filter out duplicate or unwanted elements or correcting the reading order of the document \autocite{parsingunveiled,mineru,docling}. Depending on the chosen output format, this process might lead to the loss of information, such as the loss of bounding box information for an output in Markdown format \autocite{docling_toolkit}.

Systems following the modular pipeline approach also have some inherent drawbacks. Mainly, due to handling the parsing of each structural element independly of each other, pipeline systems fail to capture information about the global context of the document, leading to semantic loss \autocite{intelligent_doc_parsing}. Additionally, because of the sequential nature of the pipeline approach, errors from different stages propagate through the pipeline \autocite{intelligent_doc_parsing,mineru_vlm}.

\subsection{End-to-End VLM models}
Due to recent recent advancements in \gls{vlm} architectures, end-to-end \gls{vlm} models have emerged as a promising alternative to traditional pipeline-based approaches. Research such as \gls{got} have demonstrated the ability of \glspl{vlm} to perform \gls{ocr} with a high accurary, while being able to extract tables, charts or mathematical formulas with a singular model \autocite{general_ocr_theory}. Contrary to pipeline-based methods, \gls{vlm}-based approaches are able to generate structured outputs directly from the input document, addressing the error propagation problem of modular pipelines \autocite{monkeyocr}. Additionally, these models demonstrate advantages in understanding the structure and hierarchy of complex documents \autocite{parsingunveiled}.\ \gls{vlm}-based approaches can be divided into two further subcategories:

\textbf{General-Purpose \glspl{vlm}:} General purpose \glspl{vlm} are not trained solely for document-centric tasks, but are still able to show promising results for \gls{dp}, due to their large parameter count and extensive training data \autocite{mineru_vlm,qwen25vl}. However, these models are often either proprietary or require extensive computational resources \autocite{mineru_vlm}. Additionally, they often struggle with documents that follow more complex layouts or contain densely packed text blocks \autocite{mineru_vlm}.

\textbf{Domain-Specific \glspl{vlm}}
Domain-specific \glspl{vlm} are trained and optimized specifically for optimal \gls{dp} \autocite{mineru_vlm,parsingunveiled,intelligent_doc_parsing}. In recent years, there has been promising developments towards domain-specific \glspl{vlm} that encapsulate \gls{dla}, content extraction and relation integration into a single model \autocite{dotsocr}. These models are able to achieve state-of-the-art performance on document parsing benchmarks, while being a fraction of the size of general-purpose \glspl{vlm} \autocite{dotsocr,mineru_vlm}. However, as \glspl{vlm} are not bound to the stages of traditional pipeline systems, there has also been additional research regarding models optimized for the direct generation of structured outputs, most notably Markdown \autocite{intelligent_doc_parsing}. However, this approach inherently leads to the loss of information, such as positional information for the extracted elements, which inherently are not included in the Markdown output, making this class of models unsuitable for the purposes of this research \autocite{dotsocr,intelligent_doc_parsing}.

Recently, there has also been research towards multi-stage \gls{vlm}-based approaches \autocite{mineru_vlm,monkeyocr}. These models use one or more \glspl{vlm} in multiple stages, aiming to encapsulate the computational efficience of pipeline approaches with the improved accuracy and structure understanding of \gls{vlm}-based methods \autocite{mineru_vlm}. However, especially when multiple \glspl{vlm} are in use, these approaches come with a further increase in complexity and computational requirements and may show suboptimal performance in tasks such as reading order inference compared to single-stage \gls{vlm}-based approaches \autocite{mineru_vlm,dotsocr}. Current challenges regarding the development of \gls{vlm}-based approaches are the risks of hallucinations, especially on longer documents \autocite{mineru_vlm,docling_toolkit}, as well as their high computational requirements and compared to modular pipeline systems \autocite{docling_toolkit}.

\section{Document Chunking}
\todo{Other usages of chunking than RAG}

Content:
\begin{itemize}
  \item Definition
  \item Role in RAG systems
  \item Different Types: Rule based, File dependent
\end{itemize}

\section{Retrieval-Augmented Generation}
While \glspl{llm} have extensive general domain knowledge due to their enormous corpora of training data, compiled from various open-domain sources \autocite{impact_dataset_rag_multi_hop}, they struggle with tasks that require domain-specific knowledge which they did not encounter during training \autocite{rag_survey}. This can lead to `hallucinations' and inaccuracies, as the model tries to synthesize a matching answer based of it's domain-wise irrelevant training data \autocite{rag_survey,chunk_size_effect_on_rag}.\ \gls{rag} addresses this limitation, extending the usage of \glspl{llm} to applications requiring extensive knowledge in a specific domain \autocite{rag}. This is achieved by retrieving information from an external knowledge source comprised of application-relevant text passages, supplying additional context to the \gls{llm} during answer generation \autocite{rag,rag_survey}.

\subsection{Tokenization}
Tokenization refers to the segmentation of text into subword units called tokens \autocite{fast_tokenization}. Tokens are the fundamental text representation for most \gls{nlp} tasks. With a granularity located between characters and words, tokens can retain linguistic meaning while also being able to represent arbitrary text with a relatively concise vocabulary \autocite{fast_tokenization}. Using tokenization any given text can essentially be represented as a list of integers, with each integer being the identifier to a specific token in the tokenizer's dictionary \autocite{token_history}. During training, the tokenizer creates it's dictionary by finding character pairings that occur with the highest frequency in the training data \autocite{token_history}. Additionally, with the multitude of different techniques for modern subword tokenization \autocite{wordpiece,sentencepiece,unigram}, the same input text can lead to drastically different outputs depending on the specific tokenizer and training data. Therefore, tokenizers always need to match the \gls{nlp} models they are used with.

\subsection{Text Embeddings}
Content:
\begin{itemize}
  \item Definition
  \item Types of embeddings
\end{itemize}

\subsection{Semantic Similarity}
Content:
\begin{itemize}
  \item Definition
  \item Role in RAG
\end{itemize}

\subsection{Architecture of Retrieval-Augmented Generation systems}
While there are many advanced and extended versions of \gls{rag} systems, for this study we will focus on the standard Naive \gls{rag} architecture as depicted in \autoref{fig:naive-rag} \autocite{rag_survey}. Naive \gls{rag} is based on the original \gls{rag} architecture proposed by \textcite{rag}. Naive \gls{rag} systems consist of two modules:

\begin{figure}[htpb]
  \centering
  \includegraphics[width=0.8\textwidth]{rag_diagram}
  \caption[Naive \gls{rag}]{Architecture of the Naive \gls{rag} system.}\label{fig:naive-rag}
\end{figure}

\textbf{Retriever:} The retriever module consists of a query encoder and an external knowledge base \autocite{rag}. It is responsible for retrieving relevant context from the knowledge base, based on the user's query \autocite{rag_survey}. The module is based on the bi-encoder architecture, with the query encoder $q$ and document encoder $d$ encoding texts into a shared embedding space \autocite{rag, dual_encoders}. The knowledge base is a vector database consisting of application-specific text passages $z$. Each passage is stored in the database as a vector embedding $d(z)$, encoded through the document encoder $d$ \autocite{rag}. To identify the relevant passages for a query $x$, $x$ is first transformed into a vector embedding $q(x)$ using the retriever's query encoder \autocite{rag_survey}. Based on the similarity scores between the query embedding and the stored chunk embeddings, the top-$k$ documents $z$ with the highest similarity scores, are then retrieved from the database \autocite{rag,rag_survey}.

\textbf{Generator:} The generator module is responsible for synthesizing the final answer based on the user's query and the passages retrieved by the retriever \autocite{rag}. Firstly, the original query $x$ and the retrieved passages $z$ are combined into a single input query \autocite{rag_survey}. The \gls{llm} is then tasked with generating the final answer $y$, conditioned on this combined input \autocite{rag_survey,rag}.

\subsection{Indexing}
In order to apply \gls{rag} systems to knowledge-intensive tasks in a specific domain, the external knowledge base needs to be created from relevant data sources. This process is referred to as Indexing \autocite{rag_survey}. Indexing begins with the preparation of the data sources into short text passages \autocite{rag_survey}. For the purpose of this study we will refer to this process as document segmentation. Document segmentation includes both \gls{dp}, the conversion of unstructured documents, such as \glspl{pdf} and images, into structured data, as well as chunking, the splitting of this data into smaller text passages called chunks. Chunking is a necessary step for \gls{rag} systems, as both \glspl{llm} and encoders are limited in the number of tokens that fit into their context window \autocite{rag_survey}. Furthermore, indexing includes the encoding of these chunks into vector embeddings. Both the embeddings and the original chunks are then stored as key-value pairs in a vector database, allowing fast and frequent searches during retrieval \autocite{rag_survey}.

% Add paragraph about optimization and how we will focus on optimizing the document segmentation process as that is super important to the performance

%The quality of the document segmentation process plays a crucial role in the overall performance of the \gls{rag} system. % Especially chunking

\section{Source Attribution}


\subsection{Bounding Boxes}
\begin{itemize}
  \item Definition
  \item Formats of Bounding boxes
  \item What do we mean when we say bounding boxes in the thesis? (normalized, ltrb)
\end{itemize}

\subsection{Intersection over Union}
According to the definition from \textcite{object_detection}, the \gls{iou} between two bounding boxes $BB_{a}$ and $BB_{b}$ is defined as described in \autoref{eq:iou}. The \gls{iou} can take on any value between 0 and 1, where a value of 0 means that there is no overlap between the two bounding boxes, and a value of 1 means that the two bounding boxes are identical. In the context of object detection, \gls{iou} is commonly used to evaluate the accuracy of predicted bounding boxes against ground truth bounding boxes \autocite{object_detection}.

\begin{equation}
  IoU(BB_{a}, BB_{b}) = \frac{\text{Area of intersection of } BB_{a} \text{ and } BB_{b}}{\text{Area of union of } BB_{a} \text{ and } BB_{b}}
  \label{eq:iou}
\end{equation}

